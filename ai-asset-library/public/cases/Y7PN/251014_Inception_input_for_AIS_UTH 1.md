---
title: "Inception AI Developer Platform (D1) Codification"
description: "Codification of Inception’s AI developer platform “D1”, a six‑week proof-of-concept foundation for building and operating multi-tenant, agentic AI applications. The materials cover the platform’s reference architecture, core services (LLM gateway/model brokerage, knowledge services, orchestration, moderation, observability), and the showcase Board Observer application migration."
contacts:
  - name: "Vinoth Rajasekar"
    email: "Vinoth.Rajasekar@bain.com"
  - name: "David Lanyi"
    email: "David.Lanyi@bain.com"
---

# Code documentation

## Source materials

- AI platform codification deck: `251014_Inception AI_Platform_Codification_v2.pptx`
- Lessons learned: `D1 Lessons Learned.docx`
- Codification summary: `Inception Platform Codification Summary.docx`

## What was built (D1 scope)

Inception’s **D1 AI developer platform** is a proof-of-concept foundation designed to help teams rapidly build, deploy, and operate **agentic** AI applications in a **secure, multi-tenant** environment. The platform was built in a **six-week sprint cadence** and used the **Board Observer** application as the primary showcase workload.

### Delivery timeline (six one-week sprints)

- **Sprint 1–2:** Monorepo + CI/CD to managed AKS dev cluster; Terraform + Helm codified infra; namespaces per environment; LLM gateway exposed; document ingestion pipeline into PGVector / Azure AI Search; initial SDK & Swagger portal.
- **Sprint 3–4:** Kubernetes RBAC + Key Vault secrets; prompt-versioning service; vLLM GPU inference path; Prometheus + Grafana; central log collection.
- **Sprint 5–6:** Multi-tenancy & BYOK security patterns; Board Observer voice chat (STT + Deepgram); role-based user management via Clerk; platform CLI for tenant spin-up; Python & TypeScript SDKs autogenerated from unified OpenAPI spec; MCP Tools API; agentic SDK; SharePoint connector as MCP tool; Langfuse prompt metrics dashboard.

## Platform capabilities (highlights)

- **MCP server / Tools API:** Secure, standardized access to platform services as tools for agent frameworks.
- **Platform control plane + CLI:** Automates tenant onboarding and isolated deployments (targeting **<30 minutes** onboarding).
- **SDK auto-generation:** Multi-language SDKs and developer portals from a unified OpenAPI specification.
- **Local models on GPU nodes:** vLLM inference path for fine-tuned/custom models (e.g., Llama-class).
- **Multi-tenant vector store:** Demonstrated secure multi-index patterns for retrieval.
- **Customer-managed keys (BYOK/CMK):** Demonstrated encryption patterns to accelerate security and compliance goals.

## Reference architecture

### Compute and tenant isolation (Kubernetes)
- **Namespace isolation per tenant:** Each customer operates in a dedicated Kubernetes namespace with RBAC and network policies.
- **Centralized cluster service:** Manages deployments, policies, and routing consistently across tenants.
- **Automated GitOps onboarding:** GitHub Actions/ArgoCD + Helm automate namespace creation, identity configuration, and workload deployment.

### Shared services and persistence
- Shared AI services (LLM, Knowledge, STT/TTS, etc.) run in a central namespace and are accessed via internal cluster networking.
- Shared persistence (Postgres, Redis, Blob Storage) is accessed through **private endpoints** and Azure Private Link.
- Data separation is enforced logically per tenant (e.g., Postgres schema/db per tenant, Redis key prefixing, storage container/prefix partitioning), with the option to migrate high-need clients to physically isolated persistence if required.

### Security model

- **SSO & identity:** Clerk integrated with Microsoft Entra ID (SAML/OIDC) for SSO and optional Microsoft OAuth tokens for Graph APIs.
- **mTLS + auth sidecar:** Inbound traffic to application pods is validated by an auth-proxy sidecar enforcing mutual TLS and validating identity tokens.
- **Secrets & least privilege:** Azure Key Vault + Kubernetes RBAC.
- **BYOK/CMK:** Two supported patterns:
  - **Option 1 (Client Vault):** Customer owns the Key Vault/HSM and grants Inception managed identity wrap/unwrap access.
  - **Option 2 (Platform Vault):** Platform hosts a dedicated vault per tenant; customer gets delegated control to create/import/rotate/delete keys.

## Core platform services (D1)

### LLM gateway / model brokerage
- LLM gateway routed requests (e.g., Portkey ➜ Azure OpenAI) and enabled a single integration surface for applications.
- A GPU inference path was established via **vLLM** for local/custom models.

### Knowledge services
- Document ingestion pipeline (Python/Celery) loads content into **PGVector** and/or **Azure AI Search**.
- Retrieval is designed to support multi-tenant indexing and access control.
- Example connector: **SharePoint** integrated as an MCP tool.

### Orchestration and agentic SDK
- Agentic approach for conversational workflows (showcase referenced **crewAI** integration).
- Agentic SDK supports multi-agent orchestration, prompt management, and tool access via MCP.

### Moderation
- Moderation services were included as part of the foundational horizontal platform layer.

### Observability and monitoring
- **Prometheus + Grafana** for infrastructure and application dashboards; centralized log collection.
- **Langfuse** for prompt metrics dashboards (usage, latency) and prompt analytics.

### Developer experience
- Unified **OpenAPI spec** drives **autogenerated Python & TypeScript SDKs** and a Swagger/developer portal.
- Platform CLI supports tenant provisioning and repeatable deployments.

## Showcase workload: Board Observer

- Migrated Board Observer application between environments within the six-week build.
- Updated chat to an **agentic** pattern and exposed platform tooling via MCP.
- Reduced document processing time to ~**2–3 minutes** (from a workflow that required uploading documents ~12 hours in advance).
- Increased unit + integration test coverage from ~**10%** to **60%+**.
- Integrated voice chat (STT + Deepgram).

## Example deployment flow (Board Observer)

1. User authenticates through **Clerk** with **Microsoft Entra ID** (SAML/OIDC); optional Graph tokens for SharePoint/OneDrive.
2. Tenant’s app pods run in the tenant namespace; inbound traffic is authenticated via a **sidecar auth proxy** enforcing **mTLS**.
3. Tenant apps call shared AI services (LLM, Knowledge, STT/TTS) via internal networking with tenant-scoped requests.
4. All services reach shared persistence (Postgres/Redis/Blob) using **Azure Private Link** and private endpoints; tenant data is logically isolated via schemas/prefixes/containers.

## Path beyond D1

The deck positions D1 as a foundation toward an enterprise-grade platform (e.g., stronger compliance readiness such as SOC2/ISO/GDPR/HIPAA, expanded governance, and broader “sovereign-ready” deployment patterns). The stated intent is to build an MVP2 on top of D1’s seed architecture.


---



# Insights, Learning & Anecdotes

## What the team learned about delivering quickly (and safely)

Across the six-week delivery, the strongest accelerators were **tight engineering cadence**, **visible progress**, and **hands-on collaboration** between platform and application teams. Weekly sprint drops and demos created a forcing function for integration, while co-testing and bi-weekly steering updates helped keep priorities aligned.

## Lessons learned on engagement model (from D1 Lessons Learned)

- **Start with a real Sprint 0:** Allocate ~1 week to align scope, deliverables, plan, timelines, and dependencies; finalize and sign the SOW early.
- **Agree Ways of Working (WoW) upfront:** Explicitly define ownership, accountability, engagement model, success metrics, and how decisions are made.
- **Ensure guaranteed client technical engagement every sprint:** Not ad hoc support—someone must be accountable as a job, with regular code checkouts and co-development.
- **Bring the whole stack into the room:** Infrastructure, platform, application, and infosec stakeholders need to be available when their constraints block progress.
- **Remove “basic enablement” blockers early:** Ensure dev laptops and tooling can run modern workflows (e.g., Docker), and shorten the ramp for external engineers.
- **Treat testing/UAT as joint work:** Quality improves when both sides share ownership of test plans, environments, and acceptance criteria.
- **Product leadership matters:** Strong engagement from Product (not only Architecture) improves prioritization and external narratives.
- **Co-author the story:** Joint SteerCo decks and shared communication reduce mismatch between what was built and what stakeholders believe was built.
- **Policy transparency is a dependency:** Better visibility into Azure policies (e.g., G42 constraints) prevents late-stage infrastructure surprises.

## Anecdotes that shaped the delivery

- **“Project greenlit on Sunday.”** The materials note there was effectively no week zero; kickoff happened immediately, and team staffing in week 1 was incomplete—which slowed initial setup and created avoidable context-switching.
- **“No client system access.”** The Board Observer migration happened on a compressed timeline while access constraints existed, making repeatable pipelines and strong dev tooling (IaC, Helm, CI/CD) more than “nice-to-haves”—they were survival tools.
- **Infrastructure policy surprises.** Limited visibility into Azure policy guardrails contributed to setup friction; resolving these earlier would have reduced time spent on environment workarounds.

## Open questions and recommended next steps (from the codification summary)

- **Ownership:** Who currently owns the AI developer platform codebase?
- **Codification access:** What access rights remain for Bain to run codification prompts?
- **Overlap:** Has any parallel codification already started (e.g., in other teams)?
- **Reuse boundaries:** Which components are approved for external pitch reuse?

Prioritized next steps captured in the summary include reviewing the architecture deck and lessons-learned notes, clarifying ownership/reuse boundaries with key stakeholders, and producing a sanitized one-pager suitable for pitches and internal repositories.
